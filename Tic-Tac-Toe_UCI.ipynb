{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este documento exploraremos y analizaremos un dataset proporcionado por el profesorado que imparte la asignatura _Aprendizaje Automático_ en la Facultad de Informática, Universidad Complutense de Madrid. \n",
    "\n",
    "Implementaremos un modelo que realice predicciones de etiquetado binario utilizando este dataset, considerando múltiples configuraciones para el modelo, observando cómo varía su precisión y eficiencia. Para llevar a cabo estas tareas, utilizaremos las librerías _matplotlib, numpy y scikit-learn_.\n",
    "\n",
    "El objetivo de este ejercicio es, por lo tanto, poner en práctica varias habilidades aprendidas durante el desarrollo de la asignatura a lo largo de los últimos meses. De esta forma, utilizaremos únicamente metodologías impartidas en la asignatura.\n",
    "\n",
    "A continuación, realizaremos la carga de librerías, datos y un breve análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evita FutureWarning de keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# ficheros .py locales\n",
    "from log_reg import LogReg # /log_reg.py\n",
    "from neural_net import NeuralNet # /neural_net.py\n",
    "from cross_validation import cv_config # /cross_validation\n",
    "import drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tic-tac-toe.data  tic-tac-toe.names  tic-tac-toe_X.csv\ttic-tac-toe_y.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:958, number of attributes:10\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/tic-tac-toe.data', header=None)\n",
    "\n",
    "print(f'number of instances:{df.shape[0]}, number of attributes:{df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns= ['p'+str(i) for i in range(0,df.shape[1]-1)] + ['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  p0 p1 p2 p3 p4 p5 p6 p7 p8         y\n",
       "0  x  x  x  x  o  o  x  o  o  positive\n",
       "1  x  x  x  x  o  o  o  x  o  positive\n",
       "2  x  x  x  x  o  o  o  o  x  positive\n",
       "3  x  x  x  x  o  o  o  b  b  positive\n",
       "4  x  x  x  x  o  o  b  o  b  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>418</td>\n",
       "      <td>378</td>\n",
       "      <td>418</td>\n",
       "      <td>378</td>\n",
       "      <td>458</td>\n",
       "      <td>378</td>\n",
       "      <td>418</td>\n",
       "      <td>378</td>\n",
       "      <td>418</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p0   p1   p2   p3   p4   p5   p6   p7   p8         y\n",
       "count   958  958  958  958  958  958  958  958  958       958\n",
       "unique    3    3    3    3    3    3    3    3    3         2\n",
       "top       x    x    x    x    x    x    x    x    x  positive\n",
       "freq    418  378  418  378  458  378  418  378  418       626"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset expone por cada tupla el contenido de las 9 posiciones del tablero de tres en raya, donde juegan dos jugadores denotados por *x* y *o*, así como la resolución de la partida, denotada con la cadena *positive* si ha ganado *x* o *negative* si ha ganado *o*. Por lo tanto, tenemos dos posibles etiquetas.\n",
    "\n",
    "Leyendo el fichero _tic-tact-toe.names_ podemos conocer brevemente cómo se exponen los valores de las variables del dataset, concluyendo que en cada posición del tablero encontraremos una de tres opciones:\n",
    "\n",
    "   > (x=player x has taken, o=player o has taken, b=blank)\n",
    "    \n",
    "Además, es relevante remarcar que se asume que el jugador *x* juega primero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos contenidos en el Dataframe *df* en arrays de Numpy para facilitar la manipulación de los datos en el código externo a este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df.columns[:-1]\n",
    "label_cols = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape(958, 9), y.shape(958,)\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(df.loc[:, feature_cols])\n",
    "y = np.asarray(df.loc[:, label_cols].ravel())\n",
    "print(f'X.shape{X.shape}, y.shape{y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(X[0])\n",
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reconocer mejor cómo se comportan los datos de *X* con respecto a sus etiquetas, *y*, dibujamos varios ejemplos en un tablero del juego *Tic tac toe*.\n",
    "\n",
    "De esta forma, podemos conocer cómo se estructuran las variables características sobre el tablero y su relación con *y*, comprendiendo así mejor la naturaleza del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 90x126 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drawing.draw_end_game(X[0], y[0], categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 90x126 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drawing.draw_end_game(X[500], y[500], categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 90x126 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drawing.draw_end_game(X[210], y[210], categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando estos ejemplos comprendemos que, efectivamente, al situarse en el tablero 3 fichas 'x' consecutivas en fila, columna o diagonal, se considera como ganador al jugador 'x'. En caso contrario, podemos afirmar que el ganador será 'o', ya que si el juego no llega a su fin por la victoria de 'x', llega a su fin por la victoria de 'o', no hay posibles empates. Este hecho encaja completamente con la naturaleza de las etiquetas *y*, ya que designan si ganó 'x' u 'o', no deja la posibilidad a empate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anticipando el análisis que llevaremos a cabo posteriormente, podemos preveer que no hay correlación entre los datos de X. Es decir, una configuración final de una partida de Tic-Tac-Toe y su resultado no guardan relación con otras configuraciones y otros resultados. De esta forma, analizando la distribución de los datos, es posible creer que construir correlaciones entre posiciones del tablero y los resultados finales (variables características y sus consecuentes etiquetas) es muy complejo por los medios que hemos estudiado en la asignatura. \n",
    "\n",
    "Los métodos utilizados a lo largo del curso para realizar predicción de clases han sido regresión logística, redes neuronales y support vector machines. De este conjunto de metodologías, las dos primeras construyen a lo largo del entrenamiento de sus modelos rectas o planos de decisión en base a la categorización de ejemplos vistos previamente. \n",
    "\n",
    "Este planteamiento colisiona, por la algoritmia utilizada hasta ahora, con la distribución de nuestros datos, ya que las variables características expresan presencia u ausencia de un jugador u otro en posiciones del tablero, las cuales no tienen una semántica relevante en el problema. Es decir, la existencia de una pieza del jugador 'x' en la posición 1,1 puede ser igual de relevante o irrelevante que si la pieza estuviera en la posicion 3,3, por ejemplo, a la hora de ganar una partida. No hay ninguna posición en el tablero que otorge una ventaja, todas las posiciones son igualmente accesibles en cualquier momento de la partida y por cualquier jugador. Esto ocurre al contrario en otros juegos de tablero como, por ejemplo, el ajedrez, juego en el cual posicionar una pieza en una posición concreta del tablero implica haber realizado cierto número de movimientos hasta llevar a la pieza a esa posición. Además, en el ajedrez, la funcionalidad (movimiento) de cada pieza puede verse afectada por su posición. Una torre situada en una esquina solo podrá ejecutar la mitad de sus posibles movimientos. \n",
    "\n",
    "En el caso del Tic-Tac-Toe, ninguna de estas implicaciones por la distribución de las piezas puede ser llevada a cabo, por lo tanto, preveemos que los modelos de regresión logística y red neuronal no serán capaces de adaptarse a los datos, no podrán construir una conclusión de los datos.\n",
    "\n",
    "En cambio, los modelos support vector machine son mucho más sofisticados y complejos que regresión logística y red neuronal, por lo tanto, creemos que podrían responder mejor a la distribución de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la manipulación de los datos tanto de *X* como de *y*, vamos a convertir el contenido de ambos arrays de datos categóricos a datos númericos.\n",
    "\n",
    "Para ello, vamos a realizar el siguiente mapeo:\n",
    "\n",
    "- **y** : lo mapearemos correspondientemente dos veces, inicialmente pasará a ser 'x'(positive) u 'o'(negative), después lo convertiremos a '1'(x) o '0'(o). Es decir, guardaremos de *y* sus datos categóricos y sus datos numéricos, permitiendo así posteriores análisis más cómodos.\n",
    "- **X** : ya que los datos iniciales ya contenían 'x' u 'o', solo realizaremos la conversión a '1'(x) o '0'(o). Mantendremos ambas versiones de *X*, al igual que hacíamos con *y*.\n",
    "\n",
    "Consideraremos de ahora en adelante: 0-->'o', 1-->'x', 2-->'b', tanto para *X* como para *y*, aunque *y* no tenga la etiqueta 'b'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proceso, definiremos dos funciones que nos ayudarán en las conversiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_nums = lambda x : 1 if x == 'x' else (0 if x == 'o' else 2)\n",
    "convert_to_nums = np.vectorize(convert_to_nums)\n",
    "\n",
    "convert_to_cats = lambda x : 'x' if x == 1 else ('o' if x == 0 else 'b')\n",
    "convert_to_cats = np.vectorize(convert_to_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X # inicialmente X ya esta en version categorica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 0 0] X.shape:(958, 9)\n"
     ]
    }
   ],
   "source": [
    "X = convert_to_nums(X_cat)\n",
    "print(X[0], f'X.shape:{X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez convertida cada variable categórica en una variable numérica, producimos tres variables numéricas _dummy_ por cada variable numérica actual.\n",
    "\n",
    "Cada posición del tablero quedará designada por tres variables numéricas que expongan los siguientes escenarios, según lo que se encuentre en el ejemplo en la posición concreta del tablero:\n",
    "- [1,0,0] es 'o'\n",
    "- [0,1,0] es 'x'\n",
    "- [0,0,1] es 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [0,1,2,3,4,5,6,7,8])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0.] X.shape:(958, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X[500], f'X.shape:{X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, eliminamos todas las terceras columnas ya que es información redudante. Con solo 2 columnas por posición del tablero podemos representar las tres posibilidades de la siguiente forma: \n",
    "- x:'10' \n",
    "- o:'00'\n",
    "- b:'01'\n",
    "\n",
    "Por lo tanto, utilizamos dos columnas como si fueran dos bits, representando las posibilidades de cada posición en base a combinaciones de bits.\n",
    "\n",
    "De esta forma, reducimos las dimensiones del dataset y, además, evitamos el fenómeno conocido como _dummy variable trap_. Las variables _dummy_ son las variables que hemos construido hasta ahora para resolver el problema, son variables que toman un valor 1 o 0 denotando la presencia o ausencia de una característica o categoría. En este caso, el escenario _dummy variable trap_ se encuentra y entiende por la correlación múltiple entre las variables que utilizamos para designar cada posición del tablero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, [0,3,6,9,12,15,18,21,24], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.] X.shape:(958, 18)\n"
     ]
    }
   ],
   "source": [
    "print(X[500], f'X.shape:{X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si interpretramos la transformación por el ejemplo *X[0]* podremos ver que es correcta al comparar el resultado con el tablero dibujado previamente sobre el mismo ejemplo. Actualizamos *num_features* para que se mantenga coherente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un proceso muy similar con *y* en la conversión a _target_ numérico, a excepción de una interpretación previa en base al etiquetado 'positive' o 'negative. Esta interpretación solo la haremos una vez, por ello no guardamos la función que lo implementa. \n",
    "\n",
    "El valor de *y* 1 denota que la tupla de datos correspondiente pertenece a la clase \"ha ganado x\" mientras que su valor 0 denota que pertenece a la clase \"no ha ganado X\", lo cual es equivalente a \"ha ganado o\" ya que debe haber ganado uno de los dos jugadores, no hay posibilidad de empate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = np.vectorize(lambda x: 'x' if x == 'positive' else 'o')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 y.shape:(958,)\n"
     ]
    }
   ],
   "source": [
    "y = convert_to_nums(y_cat)\n",
    "print(y[0], f'y.shape:{y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, probaremos diferentes tipos de modelos de predicción binaria para posteriormente realizar una comparación y conocer qué metodología de machine learning y con qué configuración ofrece mejores resultados para nuestro problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de los modelos basados en regresión logística y red neuronal de una capa oculta se encuentra en los ficheros `/log_reg.py` y `neural_net.py`. Estos ficheros exponen los modelos a través de clases cuyo objetivo es proporcionar al exterior una manipulación similar a la que exponen librerías como *scikit-learn*. El código de estos ficheros ha sido recogido de nuestras soluciones a las prácticas desarrolladas a lo largo del curso, con las modificaciones necesarias aplicadas para ser expuesto a través de clases.\n",
    "\n",
    "Además, basándose en la teoría vista en clase y en la red neuronal de una capa oculta implementada en la práctica 4, el fichero `/multilayer_neural_net.py` implementa una red neuronal de n capas ocultas en una clase, similar a los modelos comentados previamente. Hemos decidido utilizar aun así en este notebook solamente la red neuronal de una capa oculta.\n",
    "\n",
    "Creemos que encapsular los modelos en clases de esta forma facilita la manipulación de los mismos y permite una lectura de este documento más clara y sencilla. Por ello, no accederemos a métodos privados de las clases, utilizaremos accesos como `fit()`, `predict()`, etc, como si estuviéramos tratando con un modelo implementado en una librería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos X e y en local para ahorrar el cómputo utilizado en el preprocesamiento para futuras cargas del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"dataset/tic-tac-toe_X.csv\", X, delimiter=\",\")\n",
    "np.savetxt(\"dataset/tic-tac-toe_y.csv\", y, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos nuestro conjunto de datos en el 60% para dedicarlos al entrenamiento de los modelos, en el 20% para dedicarlos a validación y en el 20% para dedicarlos a la evaluación de nuestros modelos. De esta forma, podemos conocer cómo responden nuestros modelos con datos nuevos, diferentes a los utilizados en el entrenamiento. La selección de qué datos pertenecerán a qué conjunto se realiza al azar con un *seed=42*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:(574, 18),X_val.shape:(192, 18),X_test.shape:(192, 18)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape:{X_train.shape},X_val.shape:{X_val.shape},X_test.shape:{X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente probaremos con regresión logística sin regularización. Por lo tanto, en el constructor del modelo definimos `reg_term=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(num_features=num_features,\n",
    "                num_labels=num_labels,reg_term=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1]\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:65.10416666666666%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.accuracy_score(y_test,y_pred)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como preveíamos anteriormente, el modelo de regresión logística no es capaz de obtener una conclusión de los datos de entrenamiento. A continuación construiremos y entrenaremos otro modelo utilizando regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(num_features=num_features,\n",
    "                num_labels=num_labels,reg_term=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 1]\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:65.10416666666666%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.accuracy_score(y_test,y_pred)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando las etiquetas que ha predecido el modelo sobre datos nuevos podemos comprobar que siempre predice la misma clase. En este caso, siempre predice la clase 1, es decir, que gana el jugador 'x'. Por lo tanto, el 65.104% de acierto del modelo se debe a que el conjunto de datos contiene ese porcentaje de partidas etiquetadas por la clase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar términos polinómicos al conjunto de datos no debe ser solución la problemática que encuentra la regresión logística con los datos debido a la representación de las variables características a través de *one-hot encoding*. Aun así, probamos con un grado 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_poly.shape:(574, 7315)\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(4)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "num_features_poly = len(X_train_poly[0])\n",
    "print(f'X_train_poly.shape:{X_train_poly.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(num_features=num_features_poly,\n",
    "                num_labels=num_labels,reg_term=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 1]\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X=X_train_poly, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X=X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:65.10416666666666%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.accuracy_score(y_test,y_pred)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es el mismo que hemos obtenido previamente.\n",
    "\n",
    "A continuación, probaremos la regresión logística implementada por la librería *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:78.64583333333334%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.score(X_test, y_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que esta vez, utilizando este modelo, sin ninguna hiper parametrización, el resultado es correcto, a pesar de ser muy bajo. Esto se debe a que la librería *sklearn* utiliza otros algoritmos de optimización más sofisticados que le permiten al modelo adaptarse mejor a la naturaleza del problema. En concreto, por default, el modelo utilizará *liblinear*, el cual funciona correctamente en conjuntos de datos pequeños.\n",
    "\n",
    "Con el objetivo de mejorar el resultado obtenido y teniendo en mente que *sklearn* nos permite elegir el algoritmo de optimización a utilizar, probaremos dos posibilidades más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, probaremos utilizando el algoritmo *newton-cg*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0,\n",
    "                            solver='newton-cg', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=0, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:94.79166666666666%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.score(X_test, y_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el mismo algoritmo de optimización, probaremos a cambiar el parámetro *C*, cuyo valor por default es 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0,\n",
    "                            solver='newton-cg', multi_class='multinomial', C=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=0, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:96.875%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.score(X_test, y_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el porcentaje de acierto ha subido considerablemente al cambiar el algoritmo de optimización y, en menor medida, también al cambiar el parámetro *C*, el cual denota una menor regularización. Esto quiere decir que hemos reducido el sesgo del modelo, balanceándolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0,\n",
    "                            solver='newton-cg', multi_class='multinomial', C=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=0, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:96.875%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.score(X_test, y_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentando el parámetro *C* no conseguimos mejores resultados,por lo tanto, pasamos a comprobar qué resultados nos da el siguiente algoritmo de optimización, *lbfgs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0,\n",
    "                            solver='lbfgs', multi_class='multinomial', C=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg accuracy:96.875%\n"
     ]
    }
   ],
   "source": [
    "print(f'logreg accuracy:{logreg.score(X_test, y_test)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No encontramos mejoría con este algoritmo de optimización.\n",
    "\n",
    "Por lo tanto, avanzamos al siguiente apartado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado construiremos, inicialmente, una red neuronal con una capa oculta y probaremos diferentes configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_nodes = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNet(num_features=num_features,\n",
    "                 num_hidden_nodes=num_hidden_nodes, num_labels=2, reg_term=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nnet.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnet accuracy:65.10416666666666%\n"
     ]
    }
   ],
   "source": [
    "print(f'neuralnet accuracy:{nnet.accuracy_score(y_test,y_pred)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred) # siempre predice la misma clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es el mismo que hemos obtenido inicialmente con regresión logística ocurriendo lo mismo que ocurría anteriormente: el modelo siempre predice la misma clase, como podemos comprobar a continuación.\n",
    "\n",
    "Esta causalidad se debe a la implementación algorítmica utilizada tanto en regresión logística como en redes neuronales a lo largo de las prácticas de la asignatura. En las prácticas resueltas en el curso estos algoritmos respondieron como se esperaba de ellos. En cambio, en su uso en la resolución del problema que propone este dataset, no son capaces de construir hipótesis válidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos a construir una red neuronal con más nodos en la capa oculta con el objetivo de otorgarle al modelo la fuerza suficiente para poder adaptarse a los datos. Para compensar la cantidad de nodos creciente, agregamos regularización para evitar *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_nodes = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNet(num_features=num_features,\n",
    "                 num_hidden_nodes=num_hidden_nodes, num_labels=2, reg_term=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nnet.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnet accuracy:34.89583333333333%\n"
     ]
    }
   ],
   "source": [
    "print(f'neuralnet accuracy:{nnet.accuracy_score(y_test,y_pred)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_nodes = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NeuralNet(num_features=num_features,\n",
    "                 num_hidden_nodes=num_hidden_nodes, num_labels=2, reg_term=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nnet.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnet accuracy:65.10416666666666%\n"
     ]
    }
   ],
   "source": [
    "print(f'neuralnet accuracy:{nnet.accuracy_score(y_test,y_pred)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado, de nuevo, no es satisfactorio por lo explicado anteriormente.\n",
    "\n",
    "Las redes neuronales que hemos construido hasta ahora no son suficientemente potentes para responder a la distribución de nuestros datos, donde cada ejemplos es independiente del resto y no existe un correlación entre ellos como ocurría en otros problemas tratados en la asignatura. \n",
    "\n",
    "Por ello, para lograr generalizar, necesitaremos construir un modelo más sofisticado.\n",
    "Para esta tarea utilizaremos la librería *keras*, la cual nos permitirá construir una red neuronal más compleja con más capas y otros algoritmos de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos la red neuronal como una secuencia lineal de capas construida tal y como hemos estudiado en la asignatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación agregamos las siguientes capas:\n",
    "- **1ª capa oculta:** dado que el número de variables características de X tras el preprocesamiento es 18, la dimensión de entrada de esta capa debe ser 18 también. La cantidad de nodos de la capa es 9 como resultado de redondear la suma de la cantidad de variables características con la cantidad de clases a predecir entre 2. Utiliza como función de activación *ReLU (Rectified Linear Unit)* debido a su popularidad en construcciones similares a esta.\n",
    "- **2ª capa oculta:** su dimensión de entrada debe ser 9 debido a que es la dimensión de salida de la capa anterior. Además, su cantidad de nodos, seguirá el mismo razonamiento que la dimensión de salida de la capa 1ª, así como su función de activación.\n",
    "- **Capa salida:** su dimensión de entrada debe ser 9 debido a que es la dimensión de salida de la capa anterior. Su dimensión de salida será igual a la cantidad de clases a predecir. Tenemos 2 clases pero la predicción de una puede ser deducida por la predicción de la otra. Es decir, con una única unidad en la capa de salida es suficiente. Utiliza como función de activación *sigmoid* porque esta se mueve en el intervalo [0,1] y, por lo tanto, es ideal para dar el output final de la red como probabilidad en [0,1].\n",
    "\n",
    "La función *relu* cumple la siguiente expresión:\n",
    "\n",
    "$$ R(z) = max(0,z) $$\n",
    "\n",
    "La función *sigmoid* cumple con la siguiente expresión:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.add(Dense(units=9, kernel_initializer='uniform', activation='relu', input_dim=18))\n",
    "\n",
    "nnet.add(Dense(units=9, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "nnet.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos la red para configurar la red con las capas definidas previamente.\n",
    "\n",
    "Utilizamos el optimizer *Adam* debido a su bajo coste computacional y su leve carga en memoria, lo cual agiliza el entrenamiento y, como consecuencia, la posterior prueba de diferentes configuraciones. Su funcionamiento dista en cuanto al optimizer visto en la asignatura, *gradient descent*, en el trato del parámetro *learning rate* en el entrenamiento. En vez de utilizar el mismo *learning rate* a lo largo de todo el entrenamiento como hemos aprendido al desarrollar *gradient descent*, combina el planteamiento de las técnicas *Adaptive Gradient Algorithm (AdaGrad)* y *Root Mean Square Propagation (RMSProp)*. *Adam* fue propuesto por Diederik Kingma y Jimmy Ba de la Universidad de Toronto en un paper titulado [“Adam: A Method for Stochastic Optimization“](https://arxiv.org/abs/1412.6980) en ICLR, 2015. \n",
    "\n",
    "Para la decisión del optimizer a utilizar nos hemos apoyado, además, en un paper desarrollado por Sebastian Ruder y titulado [\"An overview of gradient descent optimization algorithms\"](https://arxiv.org/abs/1609.04747)\n",
    "\n",
    "La función de coste es *binary_crossentropy* debido a que la última capa utiliza *sigmoid* como función de activación y debido a que la clasificación a realizar es binaria. Se corresponde con el planteamiento que hemos utilizado en la asignatura para la función de coste en redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 271\n",
      "Trainable params: 271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos la red considerando 150 *epochs*.\n",
    "\n",
    "Utilizaremos el conjunto de datos de validación en el entrenamiento de la red con el objetivo de evitar overfitting y conseguir que nuestro modelo generalice mejor para ejemplos diferentes a los de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 574 samples, validate on 192 samples\n",
      "Epoch 1/150\n",
      "574/574 [==============================] - 0s 183us/step - loss: 0.1549 - acc: 0.9669 - val_loss: 0.2045 - val_acc: 0.9167\n",
      "Epoch 2/150\n",
      "574/574 [==============================] - 0s 240us/step - loss: 0.1481 - acc: 0.9669 - val_loss: 0.2047 - val_acc: 0.9427\n",
      "Epoch 3/150\n",
      "574/574 [==============================] - 0s 253us/step - loss: 0.1463 - acc: 0.9704 - val_loss: 0.1918 - val_acc: 0.9219\n",
      "Epoch 4/150\n",
      "574/574 [==============================] - 0s 268us/step - loss: 0.1375 - acc: 0.9739 - val_loss: 0.1848 - val_acc: 0.9323\n",
      "Epoch 5/150\n",
      "574/574 [==============================] - 0s 248us/step - loss: 0.1321 - acc: 0.9739 - val_loss: 0.1878 - val_acc: 0.9427\n",
      "Epoch 6/150\n",
      "574/574 [==============================] - 0s 311us/step - loss: 0.1352 - acc: 0.9756 - val_loss: 0.1727 - val_acc: 0.9375\n",
      "Epoch 7/150\n",
      "574/574 [==============================] - 0s 302us/step - loss: 0.1281 - acc: 0.9826 - val_loss: 0.1813 - val_acc: 0.9271\n",
      "Epoch 8/150\n",
      "574/574 [==============================] - 0s 249us/step - loss: 0.1269 - acc: 0.9826 - val_loss: 0.1623 - val_acc: 0.9479\n",
      "Epoch 9/150\n",
      "574/574 [==============================] - 0s 254us/step - loss: 0.1199 - acc: 0.9774 - val_loss: 0.1611 - val_acc: 0.9687\n",
      "Epoch 10/150\n",
      "574/574 [==============================] - 0s 320us/step - loss: 0.1163 - acc: 0.9843 - val_loss: 0.1481 - val_acc: 0.9740\n",
      "Epoch 11/150\n",
      "574/574 [==============================] - 0s 324us/step - loss: 0.1122 - acc: 0.9843 - val_loss: 0.1478 - val_acc: 0.9635\n",
      "Epoch 12/150\n",
      "574/574 [==============================] - 0s 291us/step - loss: 0.1066 - acc: 0.9861 - val_loss: 0.1490 - val_acc: 0.9583\n",
      "Epoch 13/150\n",
      "574/574 [==============================] - 0s 282us/step - loss: 0.1094 - acc: 0.9843 - val_loss: 0.1484 - val_acc: 0.9583\n",
      "Epoch 14/150\n",
      "574/574 [==============================] - 0s 260us/step - loss: 0.1040 - acc: 0.9861 - val_loss: 0.1437 - val_acc: 0.9740\n",
      "Epoch 15/150\n",
      "574/574 [==============================] - 0s 269us/step - loss: 0.0999 - acc: 0.9861 - val_loss: 0.1534 - val_acc: 0.9375\n",
      "Epoch 16/150\n",
      "574/574 [==============================] - 0s 277us/step - loss: 0.0997 - acc: 0.9913 - val_loss: 0.1293 - val_acc: 0.9844\n",
      "Epoch 17/150\n",
      "574/574 [==============================] - 0s 281us/step - loss: 0.0914 - acc: 0.9930 - val_loss: 0.1269 - val_acc: 0.9792\n",
      "Epoch 18/150\n",
      "574/574 [==============================] - 0s 280us/step - loss: 0.0915 - acc: 0.9895 - val_loss: 0.1256 - val_acc: 0.9844\n",
      "Epoch 19/150\n",
      "574/574 [==============================] - 0s 336us/step - loss: 0.0874 - acc: 0.9948 - val_loss: 0.1308 - val_acc: 0.9635\n",
      "Epoch 20/150\n",
      "574/574 [==============================] - 0s 320us/step - loss: 0.0850 - acc: 0.9930 - val_loss: 0.1246 - val_acc: 0.9687\n",
      "Epoch 21/150\n",
      "574/574 [==============================] - 0s 242us/step - loss: 0.0855 - acc: 0.9878 - val_loss: 0.1159 - val_acc: 0.9792\n",
      "Epoch 22/150\n",
      "574/574 [==============================] - 0s 178us/step - loss: 0.0806 - acc: 0.9895 - val_loss: 0.1107 - val_acc: 0.9844\n",
      "Epoch 23/150\n",
      "574/574 [==============================] - 0s 186us/step - loss: 0.0794 - acc: 0.9948 - val_loss: 0.1097 - val_acc: 0.9896\n",
      "Epoch 24/150\n",
      "574/574 [==============================] - 0s 193us/step - loss: 0.0769 - acc: 0.9930 - val_loss: 0.1088 - val_acc: 0.9896\n",
      "Epoch 25/150\n",
      "574/574 [==============================] - 0s 176us/step - loss: 0.0743 - acc: 0.9965 - val_loss: 0.1029 - val_acc: 0.9896\n",
      "Epoch 26/150\n",
      "574/574 [==============================] - 0s 161us/step - loss: 0.0724 - acc: 0.9965 - val_loss: 0.1041 - val_acc: 0.9948\n",
      "Epoch 27/150\n",
      "574/574 [==============================] - 0s 272us/step - loss: 0.0706 - acc: 0.9965 - val_loss: 0.1024 - val_acc: 0.9896\n",
      "Epoch 28/150\n",
      "574/574 [==============================] - 0s 272us/step - loss: 0.0682 - acc: 0.9983 - val_loss: 0.0985 - val_acc: 0.9896\n",
      "Epoch 29/150\n",
      "574/574 [==============================] - 0s 283us/step - loss: 0.0675 - acc: 0.9965 - val_loss: 0.1033 - val_acc: 0.9844\n",
      "Epoch 30/150\n",
      "574/574 [==============================] - 0s 229us/step - loss: 0.0659 - acc: 0.9948 - val_loss: 0.1064 - val_acc: 0.9844\n",
      "Epoch 31/150\n",
      "574/574 [==============================] - 0s 245us/step - loss: 0.0654 - acc: 0.9965 - val_loss: 0.0954 - val_acc: 0.9948\n",
      "Epoch 32/150\n",
      "574/574 [==============================] - 0s 222us/step - loss: 0.0635 - acc: 0.9965 - val_loss: 0.0902 - val_acc: 0.9896\n",
      "Epoch 33/150\n",
      "574/574 [==============================] - 0s 292us/step - loss: 0.0609 - acc: 0.9948 - val_loss: 0.0922 - val_acc: 0.9896\n",
      "Epoch 34/150\n",
      "574/574 [==============================] - 0s 296us/step - loss: 0.0601 - acc: 0.9948 - val_loss: 0.0880 - val_acc: 0.9896\n",
      "Epoch 35/150\n",
      "574/574 [==============================] - 0s 273us/step - loss: 0.0558 - acc: 0.9983 - val_loss: 0.0897 - val_acc: 0.9896\n",
      "Epoch 36/150\n",
      "574/574 [==============================] - 0s 237us/step - loss: 0.0557 - acc: 0.9965 - val_loss: 0.0863 - val_acc: 0.9896\n",
      "Epoch 37/150\n",
      "574/574 [==============================] - 0s 180us/step - loss: 0.0546 - acc: 0.9983 - val_loss: 0.0819 - val_acc: 0.9896\n",
      "Epoch 38/150\n",
      "574/574 [==============================] - 0s 129us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9896\n",
      "Epoch 39/150\n",
      "574/574 [==============================] - 0s 153us/step - loss: 0.0513 - acc: 0.9965 - val_loss: 0.0832 - val_acc: 0.9948\n",
      "Epoch 40/150\n",
      "574/574 [==============================] - 0s 119us/step - loss: 0.0502 - acc: 0.9983 - val_loss: 0.0846 - val_acc: 0.9844\n",
      "Epoch 41/150\n",
      "574/574 [==============================] - 0s 200us/step - loss: 0.0492 - acc: 0.9965 - val_loss: 0.0758 - val_acc: 0.9948\n",
      "Epoch 42/150\n",
      "574/574 [==============================] - 0s 167us/step - loss: 0.0467 - acc: 0.9983 - val_loss: 0.0775 - val_acc: 0.9896\n",
      "Epoch 43/150\n",
      "574/574 [==============================] - 0s 123us/step - loss: 0.0466 - acc: 0.9983 - val_loss: 0.0786 - val_acc: 0.9896\n",
      "Epoch 44/150\n",
      "574/574 [==============================] - 0s 198us/step - loss: 0.0506 - acc: 0.9965 - val_loss: 0.0775 - val_acc: 0.9896\n",
      "Epoch 45/150\n",
      "574/574 [==============================] - 0s 152us/step - loss: 0.0440 - acc: 0.9983 - val_loss: 0.0743 - val_acc: 0.9896\n",
      "Epoch 46/150\n",
      "574/574 [==============================] - 0s 169us/step - loss: 0.0432 - acc: 0.9965 - val_loss: 0.0734 - val_acc: 0.9948\n",
      "Epoch 47/150\n",
      "574/574 [==============================] - 0s 201us/step - loss: 0.0412 - acc: 0.9983 - val_loss: 0.0777 - val_acc: 0.9896\n",
      "Epoch 48/150\n",
      "574/574 [==============================] - 0s 151us/step - loss: 0.0434 - acc: 0.9983 - val_loss: 0.0732 - val_acc: 0.9948\n",
      "Epoch 49/150\n",
      "574/574 [==============================] - 0s 130us/step - loss: 0.0412 - acc: 0.9983 - val_loss: 0.0706 - val_acc: 0.9948\n",
      "Epoch 50/150\n",
      "574/574 [==============================] - 0s 188us/step - loss: 0.0402 - acc: 0.9983 - val_loss: 0.0674 - val_acc: 0.9948\n",
      "Epoch 51/150\n",
      "574/574 [==============================] - 0s 119us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9896\n",
      "Epoch 52/150\n",
      "574/574 [==============================] - 0s 189us/step - loss: 0.0413 - acc: 0.9965 - val_loss: 0.0707 - val_acc: 0.9948\n",
      "Epoch 53/150\n",
      "574/574 [==============================] - 0s 153us/step - loss: 0.0375 - acc: 0.9983 - val_loss: 0.0686 - val_acc: 0.9896\n",
      "Epoch 54/150\n",
      "574/574 [==============================] - 0s 127us/step - loss: 0.0352 - acc: 0.9983 - val_loss: 0.0712 - val_acc: 0.9896\n",
      "Epoch 55/150\n",
      "574/574 [==============================] - 0s 186us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.0680 - val_acc: 0.9896\n",
      "Epoch 56/150\n",
      "574/574 [==============================] - 0s 154us/step - loss: 0.0348 - acc: 0.9983 - val_loss: 0.0747 - val_acc: 0.9844\n",
      "Epoch 57/150\n",
      "574/574 [==============================] - 0s 156us/step - loss: 0.0350 - acc: 0.9965 - val_loss: 0.0647 - val_acc: 0.9948\n",
      "Epoch 58/150\n",
      "574/574 [==============================] - 0s 205us/step - loss: 0.0357 - acc: 0.9948 - val_loss: 0.0672 - val_acc: 0.9896\n",
      "Epoch 59/150\n",
      "574/574 [==============================] - 0s 155us/step - loss: 0.0323 - acc: 0.9965 - val_loss: 0.0648 - val_acc: 0.9948\n",
      "Epoch 60/150\n",
      "574/574 [==============================] - 0s 129us/step - loss: 0.0319 - acc: 0.9983 - val_loss: 0.0633 - val_acc: 0.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "574/574 [==============================] - 0s 169us/step - loss: 0.0334 - acc: 0.9965 - val_loss: 0.0615 - val_acc: 0.9948\n",
      "Epoch 62/150\n",
      "574/574 [==============================] - 0s 151us/step - loss: 0.0322 - acc: 0.9983 - val_loss: 0.0644 - val_acc: 0.9844\n",
      "Epoch 63/150\n",
      "574/574 [==============================] - 0s 147us/step - loss: 0.0303 - acc: 0.9965 - val_loss: 0.0679 - val_acc: 0.9844\n",
      "Epoch 64/150\n",
      "574/574 [==============================] - 0s 146us/step - loss: 0.0299 - acc: 0.9983 - val_loss: 0.0704 - val_acc: 0.9844\n",
      "Epoch 65/150\n",
      "574/574 [==============================] - 0s 133us/step - loss: 0.0293 - acc: 0.9965 - val_loss: 0.0574 - val_acc: 0.9896\n",
      "Epoch 66/150\n",
      "574/574 [==============================] - 0s 176us/step - loss: 0.0268 - acc: 0.9983 - val_loss: 0.0606 - val_acc: 0.9844\n",
      "Epoch 67/150\n",
      "574/574 [==============================] - 0s 121us/step - loss: 0.0274 - acc: 0.9983 - val_loss: 0.0554 - val_acc: 0.9948\n",
      "Epoch 68/150\n",
      "574/574 [==============================] - 0s 186us/step - loss: 0.0287 - acc: 0.9983 - val_loss: 0.0555 - val_acc: 0.9948\n",
      "Epoch 69/150\n",
      "574/574 [==============================] - 0s 164us/step - loss: 0.0294 - acc: 0.9948 - val_loss: 0.0703 - val_acc: 0.9844\n",
      "Epoch 70/150\n",
      "574/574 [==============================] - 0s 118us/step - loss: 0.0268 - acc: 0.9983 - val_loss: 0.0527 - val_acc: 0.9948\n",
      "Epoch 71/150\n",
      "574/574 [==============================] - 0s 175us/step - loss: 0.0260 - acc: 0.9983 - val_loss: 0.0598 - val_acc: 0.9948\n",
      "Epoch 72/150\n",
      "574/574 [==============================] - 0s 147us/step - loss: 0.0285 - acc: 0.9948 - val_loss: 0.0562 - val_acc: 0.9896\n",
      "Epoch 73/150\n",
      "574/574 [==============================] - 0s 147us/step - loss: 0.0239 - acc: 0.9965 - val_loss: 0.0526 - val_acc: 0.9896\n",
      "Epoch 74/150\n",
      "574/574 [==============================] - 0s 179us/step - loss: 0.0284 - acc: 0.9948 - val_loss: 0.0610 - val_acc: 0.9896\n",
      "Epoch 75/150\n",
      "574/574 [==============================] - 0s 112us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 0.9948\n",
      "Epoch 76/150\n",
      "574/574 [==============================] - 0s 172us/step - loss: 0.0232 - acc: 0.9983 - val_loss: 0.0518 - val_acc: 0.9948\n",
      "Epoch 77/150\n",
      "574/574 [==============================] - 0s 142us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 0.9896\n",
      "Epoch 78/150\n",
      "574/574 [==============================] - 0s 136us/step - loss: 0.0234 - acc: 0.9983 - val_loss: 0.0848 - val_acc: 0.9740\n",
      "Epoch 79/150\n",
      "574/574 [==============================] - 0s 173us/step - loss: 0.0229 - acc: 0.9983 - val_loss: 0.0517 - val_acc: 0.9948\n",
      "Epoch 80/150\n",
      "574/574 [==============================] - 0s 113us/step - loss: 0.0248 - acc: 0.9983 - val_loss: 0.0563 - val_acc: 0.9896\n",
      "Epoch 81/150\n",
      "574/574 [==============================] - 0s 171us/step - loss: 0.0216 - acc: 0.9983 - val_loss: 0.0618 - val_acc: 0.9844\n",
      "Epoch 82/150\n",
      "574/574 [==============================] - 0s 150us/step - loss: 0.0208 - acc: 0.9983 - val_loss: 0.0652 - val_acc: 0.9844\n",
      "Epoch 83/150\n",
      "574/574 [==============================] - 0s 148us/step - loss: 0.0229 - acc: 0.9983 - val_loss: 0.0573 - val_acc: 0.9948\n",
      "Epoch 84/150\n",
      "574/574 [==============================] - 0s 162us/step - loss: 0.0226 - acc: 0.9983 - val_loss: 0.0495 - val_acc: 0.9896\n",
      "Epoch 85/150\n",
      "574/574 [==============================] - 0s 123us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9896\n",
      "Epoch 86/150\n",
      "574/574 [==============================] - 0s 155us/step - loss: 0.0235 - acc: 0.9965 - val_loss: 0.0504 - val_acc: 0.9948\n",
      "Epoch 87/150\n",
      "574/574 [==============================] - 0s 120us/step - loss: 0.0191 - acc: 0.9983 - val_loss: 0.0621 - val_acc: 0.9792\n",
      "Epoch 88/150\n",
      "574/574 [==============================] - 0s 161us/step - loss: 0.0209 - acc: 0.9965 - val_loss: 0.0518 - val_acc: 0.9896\n",
      "Epoch 89/150\n",
      "574/574 [==============================] - 0s 146us/step - loss: 0.0192 - acc: 0.9983 - val_loss: 0.0481 - val_acc: 0.9948\n",
      "Epoch 90/150\n",
      "574/574 [==============================] - 0s 131us/step - loss: 0.0196 - acc: 0.9983 - val_loss: 0.0473 - val_acc: 0.9948\n",
      "Epoch 91/150\n",
      "574/574 [==============================] - 0s 177us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 0.9896\n",
      "Epoch 92/150\n",
      "574/574 [==============================] - 0s 128us/step - loss: 0.0178 - acc: 0.9965 - val_loss: 0.0468 - val_acc: 0.9896\n",
      "Epoch 93/150\n",
      "574/574 [==============================] - 0s 154us/step - loss: 0.0175 - acc: 0.9983 - val_loss: 0.0598 - val_acc: 0.9844\n",
      "Epoch 94/150\n",
      "574/574 [==============================] - 0s 146us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 0.9792\n",
      "Epoch 95/150\n",
      "574/574 [==============================] - 0s 130us/step - loss: 0.0201 - acc: 0.9983 - val_loss: 0.0480 - val_acc: 0.9896\n",
      "Epoch 96/150\n",
      "574/574 [==============================] - 0s 170us/step - loss: 0.0174 - acc: 0.9983 - val_loss: 0.0444 - val_acc: 0.9948\n",
      "Epoch 97/150\n",
      "574/574 [==============================] - 0s 117us/step - loss: 0.0188 - acc: 0.9965 - val_loss: 0.0476 - val_acc: 0.9948\n",
      "Epoch 98/150\n",
      "574/574 [==============================] - 0s 175us/step - loss: 0.0168 - acc: 0.9965 - val_loss: 0.0547 - val_acc: 0.9844\n",
      "Epoch 99/150\n",
      "574/574 [==============================] - 0s 168us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9948\n",
      "Epoch 100/150\n",
      "574/574 [==============================] - 0s 119us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 0.9948\n",
      "Epoch 101/150\n",
      "574/574 [==============================] - 0s 188us/step - loss: 0.0150 - acc: 0.9983 - val_loss: 0.0434 - val_acc: 0.9948\n",
      "Epoch 102/150\n",
      "574/574 [==============================] - 0s 177us/step - loss: 0.0152 - acc: 0.9965 - val_loss: 0.0441 - val_acc: 0.9948\n",
      "Epoch 103/150\n",
      "574/574 [==============================] - 0s 149us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 0.9948\n",
      "Epoch 104/150\n",
      "574/574 [==============================] - 0s 158us/step - loss: 0.0146 - acc: 0.9983 - val_loss: 0.0420 - val_acc: 0.9948\n",
      "Epoch 105/150\n",
      "574/574 [==============================] - 0s 123us/step - loss: 0.0179 - acc: 0.9948 - val_loss: 0.0597 - val_acc: 0.9844\n",
      "Epoch 106/150\n",
      "574/574 [==============================] - 0s 173us/step - loss: 0.0150 - acc: 0.9983 - val_loss: 0.0395 - val_acc: 0.9948\n",
      "Epoch 107/150\n",
      "574/574 [==============================] - 0s 136us/step - loss: 0.0138 - acc: 0.9983 - val_loss: 0.0409 - val_acc: 0.9948\n",
      "Epoch 108/150\n",
      "574/574 [==============================] - 0s 148us/step - loss: 0.0141 - acc: 0.9983 - val_loss: 0.0509 - val_acc: 0.9896\n",
      "Epoch 109/150\n",
      "574/574 [==============================] - 0s 166us/step - loss: 0.0146 - acc: 0.9983 - val_loss: 0.0382 - val_acc: 0.9948\n",
      "Epoch 110/150\n",
      "574/574 [==============================] - 0s 111us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 0.9896\n",
      "Epoch 111/150\n",
      "574/574 [==============================] - 0s 184us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 0.9948\n",
      "Epoch 112/150\n",
      "574/574 [==============================] - 0s 160us/step - loss: 0.0135 - acc: 0.9983 - val_loss: 0.0616 - val_acc: 0.9896\n",
      "Epoch 113/150\n",
      "574/574 [==============================] - 0s 134us/step - loss: 0.0155 - acc: 0.9983 - val_loss: 0.0412 - val_acc: 0.9896\n",
      "Epoch 114/150\n",
      "574/574 [==============================] - 0s 201us/step - loss: 0.0149 - acc: 0.9965 - val_loss: 0.0389 - val_acc: 0.9896\n",
      "Epoch 115/150\n",
      "574/574 [==============================] - 0s 163us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 0.9896\n",
      "Epoch 116/150\n",
      "574/574 [==============================] - 0s 152us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9948\n",
      "Epoch 117/150\n",
      "574/574 [==============================] - 0s 164us/step - loss: 0.0114 - acc: 0.9983 - val_loss: 0.0417 - val_acc: 0.9948\n",
      "Epoch 118/150\n",
      "574/574 [==============================] - 0s 113us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 0.9948\n",
      "Epoch 119/150\n",
      "574/574 [==============================] - 0s 173us/step - loss: 0.0111 - acc: 0.9983 - val_loss: 0.0415 - val_acc: 0.9948\n",
      "Epoch 120/150\n",
      "574/574 [==============================] - 0s 133us/step - loss: 0.0125 - acc: 0.9983 - val_loss: 0.0374 - val_acc: 0.9948\n",
      "Epoch 121/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 165us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9896\n",
      "Epoch 122/150\n",
      "574/574 [==============================] - 0s 205us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 0.9948\n",
      "Epoch 123/150\n",
      "574/574 [==============================] - 0s 145us/step - loss: 0.0103 - acc: 0.9983 - val_loss: 0.0424 - val_acc: 0.9948\n",
      "Epoch 124/150\n",
      "574/574 [==============================] - 0s 133us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9896\n",
      "Epoch 125/150\n",
      "574/574 [==============================] - 0s 161us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9948\n",
      "Epoch 126/150\n",
      "574/574 [==============================] - 0s 111us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 0.9948\n",
      "Epoch 127/150\n",
      "574/574 [==============================] - 0s 173us/step - loss: 0.0149 - acc: 0.9948 - val_loss: 0.0636 - val_acc: 0.9844\n",
      "Epoch 128/150\n",
      "574/574 [==============================] - 0s 116us/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.0414 - val_acc: 0.9948\n",
      "Epoch 129/150\n",
      "574/574 [==============================] - 0s 161us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 0.9948\n",
      "Epoch 130/150\n",
      "574/574 [==============================] - 0s 165us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 0.9948\n",
      "Epoch 131/150\n",
      "574/574 [==============================] - 0s 125us/step - loss: 0.0148 - acc: 0.9965 - val_loss: 0.0502 - val_acc: 0.9896\n",
      "Epoch 132/150\n",
      "574/574 [==============================] - 0s 160us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 0.9896\n",
      "Epoch 133/150\n",
      "574/574 [==============================] - 0s 111us/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.0430 - val_acc: 0.9948\n",
      "Epoch 134/150\n",
      "574/574 [==============================] - 0s 168us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9948\n",
      "Epoch 135/150\n",
      "574/574 [==============================] - 0s 147us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 0.9948\n",
      "Epoch 136/150\n",
      "574/574 [==============================] - 0s 161us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9948\n",
      "Epoch 137/150\n",
      "574/574 [==============================] - 0s 167us/step - loss: 0.0091 - acc: 0.9983 - val_loss: 0.0483 - val_acc: 0.9896\n",
      "Epoch 138/150\n",
      "574/574 [==============================] - 0s 118us/step - loss: 0.0114 - acc: 0.9983 - val_loss: 0.0404 - val_acc: 0.9896\n",
      "Epoch 139/150\n",
      "574/574 [==============================] - 0s 149us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 0.9948\n",
      "Epoch 140/150\n",
      "574/574 [==============================] - 0s 149us/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0396 - val_acc: 0.9948\n",
      "Epoch 141/150\n",
      "574/574 [==============================] - 0s 144us/step - loss: 0.0103 - acc: 0.9983 - val_loss: 0.0426 - val_acc: 0.9896\n",
      "Epoch 142/150\n",
      "574/574 [==============================] - 0s 172us/step - loss: 0.0108 - acc: 0.9983 - val_loss: 0.0452 - val_acc: 0.9948\n",
      "Epoch 143/150\n",
      "574/574 [==============================] - 0s 118us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 0.9948\n",
      "Epoch 144/150\n",
      "574/574 [==============================] - 0s 172us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 0.9948\n",
      "Epoch 145/150\n",
      "574/574 [==============================] - 0s 173us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 0.9948\n",
      "Epoch 146/150\n",
      "574/574 [==============================] - 0s 133us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 0.9896\n",
      "Epoch 147/150\n",
      "574/574 [==============================] - 0s 166us/step - loss: 0.0099 - acc: 0.9965 - val_loss: 0.0385 - val_acc: 0.9896\n",
      "Epoch 148/150\n",
      "574/574 [==============================] - 0s 132us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 0.9948\n",
      "Epoch 149/150\n",
      "574/574 [==============================] - 0s 149us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 0.9948\n",
      "Epoch 150/150\n",
      "574/574 [==============================] - 0s 162us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "train_history = nnet.fit(X_train, y_train, batch_size=10,\n",
    "                         epochs=num_epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el resultado del entrenamiento del modelo, dibujamos la progresión de la precisión y del error de la red neuronal construida sobre los ejemplos de entrenamiento y sobre los ejemplos de validación. Esto nos permite reconocer posibles errores de bias u overfitting, si los hubiera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f21a00cacc0>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = np.arange(0, num_epochs)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.plot(epochs_range, train_history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(epochs_range, train_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(epochs_range, train_history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(epochs_range, train_history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el coste como la precisión de ambos conjuntos de ejemplos progresan de forma ideal. El coste desciende considerablemente a lo largo del entrenamiento así como la precisión aumenta, lo cual predice que la red funciona correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenada la red, predecimos el etiquetado de los datos de *X_test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nnet.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnet accuracy:96.875%\n"
     ]
    }
   ],
   "source": [
    "print(f'neuralnet accuracy:{accuracy_score(y_test,y_pred)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es bueno, alcanzando un porcentaje de acierto realmente correcto con un tiempo de entrenamiento muy breve.\n",
    "\n",
    "Esto se debe a una correcta elección hiper paramétrica del modelo así como una construcción robusta de la red neuronal. Gracias a la librería *Keras* podemos utilizar estos ajustes en el modelo. De no ser así, tendríamos que cambiar en gran medida el compartamiento del modelo desarrollado a lo largo de las prácticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, probamos diferentes configuraciones de la red neuronal construida para intentar obtener un porcentaje de aciertos mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = Sequential()\n",
    "\n",
    "nnet.add(Dense(units=9, kernel_initializer='uniform', activation='relu', input_dim=18))\n",
    "\n",
    "nnet.add(Dense(units=9, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "nnet.add(Dense(units=9, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "nnet.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "nnet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, entrenamos la red con un número *epochs* mayor debido al aumento del número de capas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 574 samples, validate on 192 samples\n",
      "Epoch 1/200\n",
      "574/574 [==============================] - 0s 231us/step - loss: 0.0468 - acc: 0.9843 - val_loss: 0.0434 - val_acc: 0.9896\n",
      "Epoch 2/200\n",
      "574/574 [==============================] - 0s 183us/step - loss: 0.0460 - acc: 0.9826 - val_loss: 0.0477 - val_acc: 0.9896\n",
      "Epoch 3/200\n",
      "574/574 [==============================] - 0s 247us/step - loss: 0.0492 - acc: 0.9843 - val_loss: 0.0444 - val_acc: 0.9896\n",
      "Epoch 4/200\n",
      "574/574 [==============================] - 0s 333us/step - loss: 0.0448 - acc: 0.9843 - val_loss: 0.0651 - val_acc: 0.9896\n",
      "Epoch 5/200\n",
      "574/574 [==============================] - 0s 323us/step - loss: 0.0617 - acc: 0.9843 - val_loss: 0.0467 - val_acc: 0.9896\n",
      "Epoch 6/200\n",
      "574/574 [==============================] - 0s 275us/step - loss: 0.0446 - acc: 0.9861 - val_loss: 0.0472 - val_acc: 0.9896\n",
      "Epoch 7/200\n",
      "574/574 [==============================] - 0s 321us/step - loss: 0.0555 - acc: 0.9826 - val_loss: 0.0470 - val_acc: 0.9896\n",
      "Epoch 8/200\n",
      "574/574 [==============================] - 0s 273us/step - loss: 0.0531 - acc: 0.9878 - val_loss: 0.0474 - val_acc: 0.9896\n",
      "Epoch 9/200\n",
      "574/574 [==============================] - 0s 310us/step - loss: 0.0510 - acc: 0.9843 - val_loss: 0.0539 - val_acc: 0.9844\n",
      "Epoch 10/200\n",
      "574/574 [==============================] - 0s 295us/step - loss: 0.0479 - acc: 0.9843 - val_loss: 0.0477 - val_acc: 0.9896\n",
      "Epoch 11/200\n",
      "574/574 [==============================] - 0s 344us/step - loss: 0.0483 - acc: 0.9878 - val_loss: 0.0504 - val_acc: 0.9896\n",
      "Epoch 12/200\n",
      "574/574 [==============================] - 0s 363us/step - loss: 0.0618 - acc: 0.9826 - val_loss: 0.0545 - val_acc: 0.9896\n",
      "Epoch 13/200\n",
      "574/574 [==============================] - 0s 410us/step - loss: 0.0652 - acc: 0.9878 - val_loss: 0.0471 - val_acc: 0.9896\n",
      "Epoch 14/200\n",
      "574/574 [==============================] - 0s 256us/step - loss: 0.0471 - acc: 0.9878 - val_loss: 0.0500 - val_acc: 0.9896\n",
      "Epoch 15/200\n",
      "574/574 [==============================] - 0s 244us/step - loss: 0.0465 - acc: 0.9843 - val_loss: 0.0490 - val_acc: 0.9896\n",
      "Epoch 16/200\n",
      "574/574 [==============================] - 0s 249us/step - loss: 0.0517 - acc: 0.9826 - val_loss: 0.0422 - val_acc: 0.9896\n",
      "Epoch 17/200\n",
      "574/574 [==============================] - 0s 224us/step - loss: 0.0506 - acc: 0.9826 - val_loss: 0.0511 - val_acc: 0.9792\n",
      "Epoch 18/200\n",
      "574/574 [==============================] - 0s 179us/step - loss: 0.0606 - acc: 0.9774 - val_loss: 0.0451 - val_acc: 0.9896\n",
      "Epoch 19/200\n",
      "574/574 [==============================] - 0s 213us/step - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0620 - val_acc: 0.9635\n",
      "Epoch 20/200\n",
      "574/574 [==============================] - 0s 318us/step - loss: 0.0471 - acc: 0.9826 - val_loss: 0.0527 - val_acc: 0.9896\n",
      "Epoch 21/200\n",
      "574/574 [==============================] - 0s 370us/step - loss: 0.0490 - acc: 0.9843 - val_loss: 0.0517 - val_acc: 0.9896\n",
      "Epoch 22/200\n",
      "574/574 [==============================] - 0s 338us/step - loss: 0.0585 - acc: 0.9878 - val_loss: 0.0472 - val_acc: 0.9896\n",
      "Epoch 23/200\n",
      "574/574 [==============================] - 0s 327us/step - loss: 0.0541 - acc: 0.9808 - val_loss: 0.0468 - val_acc: 0.9896\n",
      "Epoch 24/200\n",
      "574/574 [==============================] - 0s 343us/step - loss: 0.0532 - acc: 0.9826 - val_loss: 0.0449 - val_acc: 0.9896\n",
      "Epoch 25/200\n",
      "574/574 [==============================] - 0s 339us/step - loss: 0.0548 - acc: 0.9826 - val_loss: 0.0460 - val_acc: 0.9896\n",
      "Epoch 26/200\n",
      "574/574 [==============================] - 0s 343us/step - loss: 0.0554 - acc: 0.9843 - val_loss: 0.0595 - val_acc: 0.9740\n",
      "Epoch 27/200\n",
      "574/574 [==============================] - 0s 333us/step - loss: 0.0489 - acc: 0.9826 - val_loss: 0.0471 - val_acc: 0.9896\n",
      "Epoch 28/200\n",
      "574/574 [==============================] - 0s 394us/step - loss: 0.0489 - acc: 0.9843 - val_loss: 0.0424 - val_acc: 0.9896\n",
      "Epoch 29/200\n",
      "574/574 [==============================] - 0s 375us/step - loss: 0.0617 - acc: 0.9826 - val_loss: 0.0642 - val_acc: 0.9844\n",
      "Epoch 30/200\n",
      "574/574 [==============================] - 0s 104us/step - loss: 0.0463 - acc: 0.9826 - val_loss: 0.0507 - val_acc: 0.9792\n",
      "Epoch 31/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0403 - acc: 0.9808 - val_loss: 0.0531 - val_acc: 0.9896\n",
      "Epoch 32/200\n",
      "574/574 [==============================] - 0s 114us/step - loss: 0.0565 - acc: 0.9791 - val_loss: 0.0451 - val_acc: 0.9896\n",
      "Epoch 33/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0483 - acc: 0.9861 - val_loss: 0.0460 - val_acc: 0.9896\n",
      "Epoch 34/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0556 - acc: 0.9826 - val_loss: 0.0480 - val_acc: 0.9792\n",
      "Epoch 35/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0554 - acc: 0.9878 - val_loss: 0.0494 - val_acc: 0.9896\n",
      "Epoch 36/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0443 - acc: 0.9843 - val_loss: 0.0517 - val_acc: 0.9740\n",
      "Epoch 37/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0436 - acc: 0.9878 - val_loss: 0.0505 - val_acc: 0.9844\n",
      "Epoch 38/200\n",
      "574/574 [==============================] - 0s 103us/step - loss: 0.0492 - acc: 0.9843 - val_loss: 0.0563 - val_acc: 0.9844\n",
      "Epoch 39/200\n",
      "574/574 [==============================] - 0s 338us/step - loss: 0.0550 - acc: 0.9826 - val_loss: 0.0524 - val_acc: 0.9896\n",
      "Epoch 40/200\n",
      "574/574 [==============================] - 0s 299us/step - loss: 0.0471 - acc: 0.9826 - val_loss: 0.0493 - val_acc: 0.9896\n",
      "Epoch 41/200\n",
      "574/574 [==============================] - 0s 170us/step - loss: 0.0492 - acc: 0.9843 - val_loss: 0.0482 - val_acc: 0.9896\n",
      "Epoch 42/200\n",
      "574/574 [==============================] - 0s 253us/step - loss: 0.0483 - acc: 0.9878 - val_loss: 0.0808 - val_acc: 0.9635\n",
      "Epoch 43/200\n",
      "574/574 [==============================] - 0s 102us/step - loss: 0.0574 - acc: 0.9808 - val_loss: 0.0492 - val_acc: 0.9896\n",
      "Epoch 44/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0469 - acc: 0.9861 - val_loss: 0.0496 - val_acc: 0.9896\n",
      "Epoch 45/200\n",
      "574/574 [==============================] - 0s 120us/step - loss: 0.0646 - acc: 0.9843 - val_loss: 0.0529 - val_acc: 0.9896\n",
      "Epoch 46/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0570 - acc: 0.9826 - val_loss: 0.0549 - val_acc: 0.9740\n",
      "Epoch 47/200\n",
      "574/574 [==============================] - 0s 102us/step - loss: 0.0491 - acc: 0.9808 - val_loss: 0.0435 - val_acc: 0.9896\n",
      "Epoch 48/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0470 - acc: 0.9791 - val_loss: 0.0447 - val_acc: 0.9896\n",
      "Epoch 49/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0434 - acc: 0.9861 - val_loss: 0.0555 - val_acc: 0.9792\n",
      "Epoch 50/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0531 - acc: 0.9826 - val_loss: 0.0481 - val_acc: 0.9896\n",
      "Epoch 51/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0492 - acc: 0.9861 - val_loss: 0.0480 - val_acc: 0.9896\n",
      "Epoch 52/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0534 - acc: 0.9826 - val_loss: 0.0609 - val_acc: 0.9740\n",
      "Epoch 53/200\n",
      "574/574 [==============================] - 0s 107us/step - loss: 0.0471 - acc: 0.9861 - val_loss: 0.0451 - val_acc: 0.9896\n",
      "Epoch 54/200\n",
      "574/574 [==============================] - 0s 106us/step - loss: 0.0451 - acc: 0.9843 - val_loss: 0.0475 - val_acc: 0.9896\n",
      "Epoch 55/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0424 - acc: 0.9826 - val_loss: 0.0472 - val_acc: 0.9844\n",
      "Epoch 56/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0513 - acc: 0.9826 - val_loss: 0.0595 - val_acc: 0.9896\n",
      "Epoch 57/200\n",
      "574/574 [==============================] - 0s 93us/step - loss: 0.0547 - acc: 0.9826 - val_loss: 0.0491 - val_acc: 0.9896\n",
      "Epoch 58/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0462 - acc: 0.9878 - val_loss: 0.0462 - val_acc: 0.9896\n",
      "Epoch 59/200\n",
      "574/574 [==============================] - 0s 246us/step - loss: 0.0497 - acc: 0.9826 - val_loss: 0.0446 - val_acc: 0.9896\n",
      "Epoch 60/200\n",
      "574/574 [==============================] - 0s 217us/step - loss: 0.0454 - acc: 0.9895 - val_loss: 0.0691 - val_acc: 0.9583\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 117us/step - loss: 0.0468 - acc: 0.9843 - val_loss: 0.0456 - val_acc: 0.9896\n",
      "Epoch 62/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0469 - acc: 0.9826 - val_loss: 0.0450 - val_acc: 0.9896\n",
      "Epoch 63/200\n",
      "574/574 [==============================] - 0s 108us/step - loss: 0.0520 - acc: 0.9843 - val_loss: 0.0628 - val_acc: 0.9635\n",
      "Epoch 64/200\n",
      "574/574 [==============================] - 0s 106us/step - loss: 0.0460 - acc: 0.9843 - val_loss: 0.0479 - val_acc: 0.9896\n",
      "Epoch 65/200\n",
      "574/574 [==============================] - 0s 110us/step - loss: 0.0438 - acc: 0.9826 - val_loss: 0.0502 - val_acc: 0.9896\n",
      "Epoch 66/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0528 - acc: 0.9826 - val_loss: 0.0459 - val_acc: 0.9896\n",
      "Epoch 67/200\n",
      "574/574 [==============================] - 0s 93us/step - loss: 0.0420 - acc: 0.9826 - val_loss: 0.0490 - val_acc: 0.9896\n",
      "Epoch 68/200\n",
      "574/574 [==============================] - 0s 93us/step - loss: 0.0452 - acc: 0.9878 - val_loss: 0.0508 - val_acc: 0.9792\n",
      "Epoch 69/200\n",
      "574/574 [==============================] - 0s 107us/step - loss: 0.0429 - acc: 0.9843 - val_loss: 0.0465 - val_acc: 0.9896\n",
      "Epoch 70/200\n",
      "574/574 [==============================] - 0s 107us/step - loss: 0.0453 - acc: 0.9843 - val_loss: 0.0554 - val_acc: 0.9687\n",
      "Epoch 71/200\n",
      "574/574 [==============================] - 0s 292us/step - loss: 0.0456 - acc: 0.9843 - val_loss: 0.0534 - val_acc: 0.9844\n",
      "Epoch 72/200\n",
      "574/574 [==============================] - 0s 104us/step - loss: 0.0488 - acc: 0.9791 - val_loss: 0.0463 - val_acc: 0.9896\n",
      "Epoch 73/200\n",
      "574/574 [==============================] - 0s 100us/step - loss: 0.0473 - acc: 0.9826 - val_loss: 0.0644 - val_acc: 0.9687\n",
      "Epoch 74/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0505 - acc: 0.9826 - val_loss: 0.0532 - val_acc: 0.9792\n",
      "Epoch 75/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0542 - acc: 0.9826 - val_loss: 0.0462 - val_acc: 0.9896\n",
      "Epoch 76/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0470 - acc: 0.9843 - val_loss: 0.0509 - val_acc: 0.9792\n",
      "Epoch 77/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0444 - acc: 0.9878 - val_loss: 0.0459 - val_acc: 0.9896\n",
      "Epoch 78/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0438 - acc: 0.9808 - val_loss: 0.0489 - val_acc: 0.9896\n",
      "Epoch 79/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0396 - acc: 0.9843 - val_loss: 0.0583 - val_acc: 0.9896\n",
      "Epoch 80/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0532 - acc: 0.9843 - val_loss: 0.0451 - val_acc: 0.9896\n",
      "Epoch 81/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0521 - acc: 0.9843 - val_loss: 0.0592 - val_acc: 0.9896\n",
      "Epoch 82/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0507 - acc: 0.9878 - val_loss: 0.0573 - val_acc: 0.9740\n",
      "Epoch 83/200\n",
      "574/574 [==============================] - 0s 178us/step - loss: 0.0417 - acc: 0.9843 - val_loss: 0.0442 - val_acc: 0.9896\n",
      "Epoch 84/200\n",
      "574/574 [==============================] - 0s 145us/step - loss: 0.0522 - acc: 0.9826 - val_loss: 0.0449 - val_acc: 0.9896\n",
      "Epoch 85/200\n",
      "574/574 [==============================] - 0s 118us/step - loss: 0.0475 - acc: 0.9843 - val_loss: 0.0436 - val_acc: 0.9896\n",
      "Epoch 86/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0527 - acc: 0.9843 - val_loss: 0.0494 - val_acc: 0.9896\n",
      "Epoch 87/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0458 - acc: 0.9843 - val_loss: 0.0661 - val_acc: 0.9687\n",
      "Epoch 88/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0478 - acc: 0.9843 - val_loss: 0.0457 - val_acc: 0.9896\n",
      "Epoch 89/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0447 - acc: 0.9861 - val_loss: 0.0498 - val_acc: 0.9896\n",
      "Epoch 90/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0761 - val_acc: 0.9583\n",
      "Epoch 91/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0536 - acc: 0.9791 - val_loss: 0.0479 - val_acc: 0.9896\n",
      "Epoch 92/200\n",
      "574/574 [==============================] - 0s 277us/step - loss: 0.0461 - acc: 0.9843 - val_loss: 0.0454 - val_acc: 0.9896\n",
      "Epoch 93/200\n",
      "574/574 [==============================] - 0s 136us/step - loss: 0.0472 - acc: 0.9826 - val_loss: 0.0420 - val_acc: 0.9896\n",
      "Epoch 94/200\n",
      "574/574 [==============================] - 0s 101us/step - loss: 0.0464 - acc: 0.9826 - val_loss: 0.0683 - val_acc: 0.9740\n",
      "Epoch 95/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0539 - acc: 0.9878 - val_loss: 0.0420 - val_acc: 0.9896\n",
      "Epoch 96/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0530 - acc: 0.9826 - val_loss: 0.0458 - val_acc: 0.9896\n",
      "Epoch 97/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0659 - acc: 0.9791 - val_loss: 0.0474 - val_acc: 0.9896\n",
      "Epoch 98/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0483 - acc: 0.9843 - val_loss: 0.0517 - val_acc: 0.9896\n",
      "Epoch 99/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0526 - val_acc: 0.9740\n",
      "Epoch 100/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0433 - acc: 0.9826 - val_loss: 0.0458 - val_acc: 0.9896\n",
      "Epoch 101/200\n",
      "574/574 [==============================] - 0s 100us/step - loss: 0.0511 - acc: 0.9861 - val_loss: 0.0440 - val_acc: 0.9896\n",
      "Epoch 102/200\n",
      "574/574 [==============================] - 0s 120us/step - loss: 0.0440 - acc: 0.9843 - val_loss: 0.0609 - val_acc: 0.9687\n",
      "Epoch 103/200\n",
      "574/574 [==============================] - 0s 279us/step - loss: 0.0477 - acc: 0.9826 - val_loss: 0.0445 - val_acc: 0.9896\n",
      "Epoch 104/200\n",
      "574/574 [==============================] - 0s 108us/step - loss: 0.0447 - acc: 0.9843 - val_loss: 0.0844 - val_acc: 0.9531\n",
      "Epoch 105/200\n",
      "574/574 [==============================] - 0s 126us/step - loss: 0.0573 - acc: 0.9756 - val_loss: 0.0568 - val_acc: 0.9896\n",
      "Epoch 106/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0475 - acc: 0.9861 - val_loss: 0.0672 - val_acc: 0.9635\n",
      "Epoch 107/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0439 - acc: 0.9878 - val_loss: 0.0478 - val_acc: 0.9896\n",
      "Epoch 108/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0489 - acc: 0.9861 - val_loss: 0.0705 - val_acc: 0.9531\n",
      "Epoch 109/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0502 - acc: 0.9843 - val_loss: 0.0482 - val_acc: 0.9896\n",
      "Epoch 110/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0449 - acc: 0.9861 - val_loss: 0.0445 - val_acc: 0.9896\n",
      "Epoch 111/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0526 - acc: 0.9826 - val_loss: 0.0634 - val_acc: 0.9896\n",
      "Epoch 112/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0532 - acc: 0.9808 - val_loss: 0.0474 - val_acc: 0.9896\n",
      "Epoch 113/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0492 - acc: 0.9808 - val_loss: 0.0492 - val_acc: 0.9896\n",
      "Epoch 114/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0548 - acc: 0.9774 - val_loss: 0.0545 - val_acc: 0.9896\n",
      "Epoch 115/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0511 - acc: 0.9843 - val_loss: 0.0723 - val_acc: 0.9583\n",
      "Epoch 116/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0537 - acc: 0.9878 - val_loss: 0.0434 - val_acc: 0.9896\n",
      "Epoch 117/200\n",
      "574/574 [==============================] - 0s 90us/step - loss: 0.0495 - acc: 0.9843 - val_loss: 0.0463 - val_acc: 0.9896\n",
      "Epoch 118/200\n",
      "574/574 [==============================] - 0s 90us/step - loss: 0.0418 - acc: 0.9861 - val_loss: 0.0510 - val_acc: 0.9792\n",
      "Epoch 119/200\n",
      "574/574 [==============================] - 0s 197us/step - loss: 0.0432 - acc: 0.9861 - val_loss: 0.0475 - val_acc: 0.9896\n",
      "Epoch 120/200\n",
      "574/574 [==============================] - 0s 351us/step - loss: 0.0485 - acc: 0.9843 - val_loss: 0.0573 - val_acc: 0.9896\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 179us/step - loss: 0.0546 - acc: 0.9843 - val_loss: 0.0504 - val_acc: 0.9896\n",
      "Epoch 122/200\n",
      "574/574 [==============================] - 0s 156us/step - loss: 0.0511 - acc: 0.9843 - val_loss: 0.0533 - val_acc: 0.9896\n",
      "Epoch 123/200\n",
      "574/574 [==============================] - 0s 227us/step - loss: 0.0541 - acc: 0.9808 - val_loss: 0.0452 - val_acc: 0.9896\n",
      "Epoch 124/200\n",
      "574/574 [==============================] - 0s 265us/step - loss: 0.0468 - acc: 0.9843 - val_loss: 0.0494 - val_acc: 0.9896\n",
      "Epoch 125/200\n",
      "574/574 [==============================] - 0s 215us/step - loss: 0.0495 - acc: 0.9826 - val_loss: 0.0528 - val_acc: 0.9896\n",
      "Epoch 126/200\n",
      "574/574 [==============================] - 0s 234us/step - loss: 0.0508 - acc: 0.9843 - val_loss: 0.0470 - val_acc: 0.9896\n",
      "Epoch 127/200\n",
      "574/574 [==============================] - 0s 169us/step - loss: 0.0475 - acc: 0.9861 - val_loss: 0.0524 - val_acc: 0.9844\n",
      "Epoch 128/200\n",
      "574/574 [==============================] - 0s 172us/step - loss: 0.0542 - acc: 0.9843 - val_loss: 0.0482 - val_acc: 0.9896\n",
      "Epoch 129/200\n",
      "574/574 [==============================] - 0s 175us/step - loss: 0.0520 - acc: 0.9878 - val_loss: 0.0513 - val_acc: 0.9844\n",
      "Epoch 130/200\n",
      "574/574 [==============================] - 0s 173us/step - loss: 0.0497 - acc: 0.9861 - val_loss: 0.0454 - val_acc: 0.9896\n",
      "Epoch 131/200\n",
      "574/574 [==============================] - 0s 170us/step - loss: 0.0517 - acc: 0.9843 - val_loss: 0.0443 - val_acc: 0.9896\n",
      "Epoch 132/200\n",
      "574/574 [==============================] - 0s 160us/step - loss: 0.0437 - acc: 0.9808 - val_loss: 0.0693 - val_acc: 0.9896\n",
      "Epoch 133/200\n",
      "574/574 [==============================] - 0s 167us/step - loss: 0.0636 - acc: 0.9843 - val_loss: 0.0442 - val_acc: 0.9896\n",
      "Epoch 134/200\n",
      "574/574 [==============================] - 0s 175us/step - loss: 0.0486 - acc: 0.9913 - val_loss: 0.0462 - val_acc: 0.9896\n",
      "Epoch 135/200\n",
      "574/574 [==============================] - 0s 149us/step - loss: 0.0509 - acc: 0.9861 - val_loss: 0.0593 - val_acc: 0.9687\n",
      "Epoch 136/200\n",
      "574/574 [==============================] - 0s 181us/step - loss: 0.0417 - acc: 0.9913 - val_loss: 0.0459 - val_acc: 0.9896\n",
      "Epoch 137/200\n",
      "574/574 [==============================] - 0s 127us/step - loss: 0.0472 - acc: 0.9808 - val_loss: 0.0453 - val_acc: 0.9896\n",
      "Epoch 138/200\n",
      "574/574 [==============================] - 0s 139us/step - loss: 0.0585 - acc: 0.9791 - val_loss: 0.0469 - val_acc: 0.9896\n",
      "Epoch 139/200\n",
      "574/574 [==============================] - 0s 121us/step - loss: 0.0528 - acc: 0.9843 - val_loss: 0.0634 - val_acc: 0.9687\n",
      "Epoch 140/200\n",
      "574/574 [==============================] - 0s 93us/step - loss: 0.0465 - acc: 0.9878 - val_loss: 0.0463 - val_acc: 0.9896\n",
      "Epoch 141/200\n",
      "574/574 [==============================] - 0s 118us/step - loss: 0.0550 - acc: 0.9808 - val_loss: 0.0508 - val_acc: 0.9896\n",
      "Epoch 142/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0562 - acc: 0.9843 - val_loss: 0.0439 - val_acc: 0.9896\n",
      "Epoch 143/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0469 - acc: 0.9826 - val_loss: 0.0472 - val_acc: 0.9896\n",
      "Epoch 144/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0553 - acc: 0.9826 - val_loss: 0.0559 - val_acc: 0.9740\n",
      "Epoch 145/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0575 - acc: 0.9878 - val_loss: 0.0473 - val_acc: 0.9896\n",
      "Epoch 146/200\n",
      "574/574 [==============================] - 0s 100us/step - loss: 0.0513 - acc: 0.9861 - val_loss: 0.0509 - val_acc: 0.9896\n",
      "Epoch 147/200\n",
      "574/574 [==============================] - 0s 110us/step - loss: 0.0479 - acc: 0.9861 - val_loss: 0.0480 - val_acc: 0.9896\n",
      "Epoch 148/200\n",
      "574/574 [==============================] - 0s 135us/step - loss: 0.0554 - acc: 0.9808 - val_loss: 0.0526 - val_acc: 0.9896\n",
      "Epoch 149/200\n",
      "574/574 [==============================] - 0s 133us/step - loss: 0.0481 - acc: 0.9878 - val_loss: 0.0456 - val_acc: 0.9896\n",
      "Epoch 150/200\n",
      "574/574 [==============================] - 0s 186us/step - loss: 0.0434 - acc: 0.9808 - val_loss: 0.0479 - val_acc: 0.9896\n",
      "Epoch 151/200\n",
      "574/574 [==============================] - 0s 157us/step - loss: 0.0455 - acc: 0.9826 - val_loss: 0.0494 - val_acc: 0.9896\n",
      "Epoch 152/200\n",
      "574/574 [==============================] - 0s 136us/step - loss: 0.0562 - acc: 0.9843 - val_loss: 0.0533 - val_acc: 0.9896\n",
      "Epoch 153/200\n",
      "574/574 [==============================] - 0s 106us/step - loss: 0.0491 - acc: 0.9843 - val_loss: 0.0508 - val_acc: 0.9896\n",
      "Epoch 154/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0413 - acc: 0.9878 - val_loss: 0.0457 - val_acc: 0.9896\n",
      "Epoch 155/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0470 - acc: 0.9843 - val_loss: 0.0523 - val_acc: 0.9792\n",
      "Epoch 156/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0453 - acc: 0.9878 - val_loss: 0.0483 - val_acc: 0.9896\n",
      "Epoch 157/200\n",
      "574/574 [==============================] - 0s 94us/step - loss: 0.0545 - acc: 0.9843 - val_loss: 0.0492 - val_acc: 0.9896\n",
      "Epoch 158/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0522 - acc: 0.9861 - val_loss: 0.0574 - val_acc: 0.9896\n",
      "Epoch 159/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0468 - acc: 0.9878 - val_loss: 0.0598 - val_acc: 0.9896\n",
      "Epoch 160/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0507 - acc: 0.9843 - val_loss: 0.0481 - val_acc: 0.9896\n",
      "Epoch 161/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0525 - acc: 0.9861 - val_loss: 0.0444 - val_acc: 0.9896\n",
      "Epoch 162/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0468 - acc: 0.9861 - val_loss: 0.0440 - val_acc: 0.9896\n",
      "Epoch 163/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0466 - acc: 0.9826 - val_loss: 0.0472 - val_acc: 0.9896\n",
      "Epoch 164/200\n",
      "574/574 [==============================] - 0s 92us/step - loss: 0.0432 - acc: 0.9861 - val_loss: 0.0496 - val_acc: 0.9792\n",
      "Epoch 165/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0523 - acc: 0.9843 - val_loss: 0.0572 - val_acc: 0.9635\n",
      "Epoch 166/200\n",
      "574/574 [==============================] - 0s 91us/step - loss: 0.0495 - acc: 0.9826 - val_loss: 0.0579 - val_acc: 0.9740\n",
      "Epoch 167/200\n",
      "574/574 [==============================] - 0s 120us/step - loss: 0.0491 - acc: 0.9826 - val_loss: 0.0473 - val_acc: 0.9896\n",
      "Epoch 168/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0488 - acc: 0.9843 - val_loss: 0.0484 - val_acc: 0.9896\n",
      "Epoch 169/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0460 - acc: 0.9843 - val_loss: 0.1095 - val_acc: 0.9427\n",
      "Epoch 170/200\n",
      "574/574 [==============================] - 0s 139us/step - loss: 0.0573 - acc: 0.9826 - val_loss: 0.0469 - val_acc: 0.9896\n",
      "Epoch 171/200\n",
      "574/574 [==============================] - 0s 115us/step - loss: 0.0440 - acc: 0.9861 - val_loss: 0.0458 - val_acc: 0.9896\n",
      "Epoch 172/200\n",
      "574/574 [==============================] - 0s 96us/step - loss: 0.0398 - acc: 0.9878 - val_loss: 0.0600 - val_acc: 0.9687\n",
      "Epoch 173/200\n",
      "574/574 [==============================] - 0s 93us/step - loss: 0.0487 - acc: 0.9808 - val_loss: 0.0477 - val_acc: 0.9896\n",
      "Epoch 174/200\n",
      "574/574 [==============================] - 0s 95us/step - loss: 0.0500 - acc: 0.9826 - val_loss: 0.0522 - val_acc: 0.9896\n",
      "Epoch 175/200\n",
      "574/574 [==============================] - 0s 146us/step - loss: 0.0515 - acc: 0.9826 - val_loss: 0.0820 - val_acc: 0.9479\n",
      "Epoch 176/200\n",
      "574/574 [==============================] - 0s 147us/step - loss: 0.0473 - acc: 0.9843 - val_loss: 0.0459 - val_acc: 0.9896\n",
      "Epoch 177/200\n",
      "574/574 [==============================] - 0s 210us/step - loss: 0.0442 - acc: 0.9843 - val_loss: 0.0575 - val_acc: 0.9896\n",
      "Epoch 178/200\n",
      "574/574 [==============================] - 0s 340us/step - loss: 0.0484 - acc: 0.9878 - val_loss: 0.0442 - val_acc: 0.9896\n",
      "Epoch 179/200\n",
      "574/574 [==============================] - 0s 286us/step - loss: 0.0486 - acc: 0.9861 - val_loss: 0.0499 - val_acc: 0.9896\n",
      "Epoch 180/200\n",
      "574/574 [==============================] - 0s 111us/step - loss: 0.0529 - acc: 0.9808 - val_loss: 0.0536 - val_acc: 0.9896\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574/574 [==============================] - 0s 168us/step - loss: 0.0500 - acc: 0.9861 - val_loss: 0.0455 - val_acc: 0.9896\n",
      "Epoch 182/200\n",
      "574/574 [==============================] - 0s 359us/step - loss: 0.0517 - acc: 0.9826 - val_loss: 0.0664 - val_acc: 0.9896\n",
      "Epoch 183/200\n",
      "574/574 [==============================] - 0s 231us/step - loss: 0.0619 - acc: 0.9843 - val_loss: 0.0443 - val_acc: 0.9896\n",
      "Epoch 184/200\n",
      "574/574 [==============================] - 0s 243us/step - loss: 0.0475 - acc: 0.9843 - val_loss: 0.0459 - val_acc: 0.9896\n",
      "Epoch 185/200\n",
      "574/574 [==============================] - 0s 253us/step - loss: 0.0432 - acc: 0.9843 - val_loss: 0.0564 - val_acc: 0.9740\n",
      "Epoch 186/200\n",
      "574/574 [==============================] - 0s 180us/step - loss: 0.0531 - acc: 0.9843 - val_loss: 0.0480 - val_acc: 0.9896\n",
      "Epoch 187/200\n",
      "574/574 [==============================] - 0s 131us/step - loss: 0.0514 - acc: 0.9843 - val_loss: 0.0492 - val_acc: 0.9896\n",
      "Epoch 188/200\n",
      "574/574 [==============================] - 0s 154us/step - loss: 0.0450 - acc: 0.9861 - val_loss: 0.0815 - val_acc: 0.9531\n",
      "Epoch 189/200\n",
      "574/574 [==============================] - 0s 100us/step - loss: 0.0548 - acc: 0.9808 - val_loss: 0.0478 - val_acc: 0.9896\n",
      "Epoch 190/200\n",
      "574/574 [==============================] - 0s 101us/step - loss: 0.0533 - acc: 0.9843 - val_loss: 0.0563 - val_acc: 0.9896\n",
      "Epoch 191/200\n",
      "574/574 [==============================] - 0s 107us/step - loss: 0.0413 - acc: 0.9861 - val_loss: 0.0463 - val_acc: 0.9896\n",
      "Epoch 192/200\n",
      "574/574 [==============================] - 0s 98us/step - loss: 0.0709 - acc: 0.9808 - val_loss: 0.0508 - val_acc: 0.9896\n",
      "Epoch 193/200\n",
      "574/574 [==============================] - 0s 108us/step - loss: 0.0485 - acc: 0.9878 - val_loss: 0.0461 - val_acc: 0.9896\n",
      "Epoch 194/200\n",
      "574/574 [==============================] - 0s 127us/step - loss: 0.0461 - acc: 0.9826 - val_loss: 0.0441 - val_acc: 0.9896\n",
      "Epoch 195/200\n",
      "574/574 [==============================] - 0s 115us/step - loss: 0.0465 - acc: 0.9808 - val_loss: 0.0473 - val_acc: 0.9896\n",
      "Epoch 196/200\n",
      "574/574 [==============================] - 0s 112us/step - loss: 0.0486 - acc: 0.9861 - val_loss: 0.0467 - val_acc: 0.9896\n",
      "Epoch 197/200\n",
      "574/574 [==============================] - 0s 113us/step - loss: 0.0491 - acc: 0.9843 - val_loss: 0.0575 - val_acc: 0.9896\n",
      "Epoch 198/200\n",
      "574/574 [==============================] - 0s 110us/step - loss: 0.0459 - acc: 0.9843 - val_loss: 0.0467 - val_acc: 0.9896\n",
      "Epoch 199/200\n",
      "574/574 [==============================] - 0s 99us/step - loss: 0.0466 - acc: 0.9861 - val_loss: 0.0521 - val_acc: 0.9792\n",
      "Epoch 200/200\n",
      "574/574 [==============================] - 0s 97us/step - loss: 0.0449 - acc: 0.9826 - val_loss: 0.0504 - val_acc: 0.9896\n"
     ]
    }
   ],
   "source": [
    "train_history = nnet.fit(X_train, y_train, batch_size=10,\n",
    "                         epochs=num_epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f21a83076d8>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = np.arange(0, num_epochs)\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.plot(epochs_range, train_history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(epochs_range, train_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(epochs_range, train_history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(epochs_range, train_history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado del entrenamiento es realmente similar al obtenido previamente: exitoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nnet.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnet accuracy:96.875%\n"
     ]
    }
   ],
   "source": [
    "print(f'neuralnet accuracy:{accuracy_score(y_test,y_pred)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es el mismo. Quiere decir que ya alcanzó una configuración óptima el modelo con la construcción anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, consideramos que no podemos obtener mejores resultados agregando más capas aún a la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los parámetros que vamos a utilizar inicialmente para la construcción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, sigma = 2.0, 1.0\n",
    "gamma = lambda s: 1/(2*s**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=C, gamma=gamma(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy:95.83333333333334%\n"
     ]
    }
   ],
   "source": [
    "print(f'svm accuracy:{accuracy_score(y_test,y_pred)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probaremos varias configuraciones de parámetros C y sigma a través del método cv_config() que prueba combinaciones de diferentes C con diferentes sigma utilizando la metodología de validación vista en la asignatura. Para ello, utiliza los datos de entrenamiento y los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:98.95833333333334%, config:(C=10.0,sigma=3.0)\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf') # modelo vacio\n",
    "scores, configs = cv_config(svm, train_X=X_train,\n",
    "                            train_y=y_train, val_X=X_val, val_y=y_val)\n",
    "best_config_index = np.argmax(scores)\n",
    "best_C = configs[best_config_index][0]\n",
    "best_sigma = configs[best_config_index][1]\n",
    "print(f'best score:{scores[best_config_index]*100}%,'\n",
    "      +f' config:(C={best_C},'\n",
    "      +f'sigma={best_sigma})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez conocemos los mejores parámetros posibles para el modelo, los utilizamos para conocer qué porcentaje de acierto obtenemos sobre el conjunto de datos *X_test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=best_C, gamma=gamma(best_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05555555555555555,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm accuracy:96.875%\n"
     ]
    }
   ],
   "source": [
    "print(f'svm accuracy:{accuracy_score(y_test,y_pred)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es muy bueno, es el mismo que obteníamos previamente con la red construida con *Keras*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACEHOLDER: hablar sobre el uso de arboles de decision en los papers citados en la web del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decission tree accuracy:88.02083333333334%\n"
     ]
    }
   ],
   "source": [
    "print(f'decission tree accuracy:{dtree.score(X_test, y_test)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/willkoehrsen/visualize-a-decision-tree-w-python-scikit-learn\n",
    "import graphviz \n",
    "from sklearn.tree import export_graphviz  \n",
    "\n",
    "dot_data = export_graphviz(dtree, out_file='dtree.dot', class_names=['x','o'],\n",
    "                           filled=True, rounded=True,\n",
    "                           special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 0 # 2 para cargar a cada ejecucion los modulos. 0 para no cargar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLACEHOLDER "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
